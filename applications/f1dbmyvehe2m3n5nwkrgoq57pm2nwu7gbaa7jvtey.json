{
  "Version": "1.3",
  "ID": "f1dbmyvehe2m3n5nwkrgoq57pm2nwu7gbaa7jvtey",
  "Issue Number": "25",
  "Client": {
    "Name": "ALLENAI",
    "Region": "United States",
    "Industry": "IT & Technology Services",
    "Website": "https://allenai.org/",
    "Social Media": "info@allenai.org",
    "Social Media Type": "Other",
    "Role": "Data Preparer"
  },
  "Project": {
    "Brief history of your project and organization": "Ai2's mission is to advance AI through true openness. We go beyond just releasing model weights - we provide our training code, training data, our model weights, and our recipes. We hope that by sharing our full model pipelines freely and openly, we’re empowering the community to build the next generation of AI tools and applications.",
    "Is this project associated with other projects/ecosystem stakeholders?": "No",
    "Describe the data being stored onto Filecoin": "Datasets are the foundation of AI models, and their content holds the key to a better understanding of how models work and how to make them more useful, efficient, and safe. We’re committed to creating and sharing open datasets that can help move the field forward.",
    "Where was the data currently stored in this dataset sourced from": "AWS Cloud",
    "How do you plan to prepare the dataset": "We used the Go language to develop a set of tools that automatically download, cut, package data, and place orders. The tool will download the data set file from AWS, package the data set into a car file of the corresponding size by setting parameters such as sector size, and then distribute the car file to each SP through bandwidth and hard disk mail. Then, we use Boost to issue orders offline to let the SP start packaging using the Lotus program.",
    "Please share a sample of the data (a link to a file, an image, a table, etc., are good ways to do this.)": "aws s3 ls --no-sign-request s3://ai2-public-datasets/ 42.0 TiB",
    "Confirm that this is a public dataset that can be retrieved by anyone on the network (i.e., no specific permissions or access rights are required to view the data)": "[x] I confirm",
    "What is the expected retrieval frequency for this data": "Yearly",
    "For how long do you plan to keep this dataset stored on Filecoin": "1.5 to 2 years",
    "In which geographies do you plan on making storage deals": "Greater China, Asia other than Greater China, North America, South America, Europe",
    "How will you be distributing your data to storage providers": "HTTP or FTP server",
    "Please list the provider IDs and location of the storage providers you will be working with. Note that it is a requirement to list a minimum of 5 unique provider IDs, and that your client address will be verified against this list in the future": "f03315260 Germany\nf03619143 HongKong\nf03619150 Singapore\nf03368008 Vietnam\nf03607310 Brazil",
    "Can you confirm that you will follow the Fil+ guideline (Data owner should engage at least 4 SPs and no single SP ID should receive >30% of a client's allocated DataCap)": "Yes"
  },
  "Datacap": {
    "Type": "ldn-v3",
    "Data Type": "Slingshot",
    "Total Requested Amount": "300TiB",
    "Single Size Dataset": "60TiB",
    "Replicas": 5,
    "Weekly Allocation": "300TiB"
  },
  "Lifecycle": {
    "State": "Submitted",
    "Validated At": "",
    "Validated By": "",
    "Active": true,
    "Updated At": "2025-08-24 03:53:59.876922225 UTC",
    "Active Request ID": "",
    "On Chain Address": "f1dbmyvehe2m3n5nwkrgoq57pm2nwu7gbaa7jvtey",
    "Multisig Address": "false",
    "edited": false
  },
  "Allocation Requests": []
}